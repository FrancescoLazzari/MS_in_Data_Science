{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup**"
      ],
      "metadata": {
        "id": "BBx2plmvC1Vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###First time executing"
      ],
      "metadata": {
        "id": "GLRnWIniC8VD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBaA2AuRerRm"
      },
      "source": [
        "Set the ***first_time_executing*** variable to ***True*** if it's the first time executing the notebook\n",
        "\n",
        "After executed, it will ask you to upload a file needed to download the dataset directly into Google Colab. To obtain that file:\n",
        "\n",
        "*   Go to [Kaggle.com](https://www.kaggle.com/)\n",
        "*   Go to your account\n",
        "*   Under the voice API select \"*Create new Token*\"\n",
        "\n",
        "This will download a *kaggle.json* file. Please upload that file in order to continue.\n",
        "\n",
        "<br/>\n",
        "\n",
        "**More info:**\n",
        "The file contains your personal Kaggle API key: it will allow to download the dataset directly into Google Colab without downloading it in Google Drive beforehand (and without mounting the Drive).\n",
        "\n",
        "The dataset will be unzipped directly in the current working directory (/content)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WldFWU6GIN2k"
      },
      "outputs": [],
      "source": [
        "first_time_executing = True\n",
        "\n",
        "if first_time_executing:\n",
        "\n",
        "  from google.colab import files\n",
        "  import os\n",
        "\n",
        "  !pip install -q kaggle\n",
        "\n",
        "  # Please upload the kaggle.json file you downlad from going to kaggle.com > Your account > API > Create new Token\n",
        "  files.upload()\n",
        "\n",
        "  !mkdir ~/.kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "  dataset_full_name = \"tawsifurrahman/covid19-radiography-database\" # The dataset name must be: Username/Dataset_name\n",
        "  !kaggle datasets download {dataset_full_name}\n",
        "\n",
        "  dataset_name = os.path.basename(os.path.normpath(dataset_full_name))\n",
        "  !unzip {dataset_name}.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and Parameters"
      ],
      "metadata": {
        "id": "4D_6Vw2PDJOD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvQ5VPEFrSfG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "dataset_path = 'COVID-19_Radiography_Dataset'\n",
        "balanced_dataset_path = 'COVID-19_Radiography_Dataset_Balanced'\n",
        "new_dataset_name = 'Covid_Dataset'\n",
        "train_csv_path = 'train.csv'\n",
        "test_csv_path = 'test.csv'\n",
        "train_dir = os.path.join(new_dataset_name, 'train')\n",
        "test_dir = os.path.join(new_dataset_name, 'test')\n",
        "\n",
        "# classes = ['COVID', 'Normal', 'Viral Pneumonia']\n",
        "classes = ['COVID', 'Normal']\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.09\n",
        "TEST_SIZE = 0.2\n",
        "SEED = 42\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "normalize = False\n",
        "\n",
        "# If you want to train a convolutional set is_conv to True, if you want to train a fully connected, set is_conv to False\n",
        "is_conv = True\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocessing**"
      ],
      "metadata": {
        "id": "GVTkYCXdg8Q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Balancing"
      ],
      "metadata": {
        "id": "6_MFPSGsteTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Delete Lung Opacity Class"
      ],
      "metadata": {
        "id": "qbUriMJWtpnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copytree(dataset_path, balanced_dataset_path)\n",
        "\n",
        "lung_opacity_dir = os.path.join(balanced_dataset_path, 'Lung_Opacity')\n",
        "\n",
        "try:\n",
        "  shutil.rmtree(lung_opacity_dir)\n",
        "  print(f\"Successfully deleted: {lung_opacity_dir}\")\n",
        "except OSError as e:\n",
        "  print(f\"Error: {lung_opacity_dir} - {e}\")"
      ],
      "metadata": {
        "id": "Lsy-DtypIINF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Balance Normal and Covid class"
      ],
      "metadata": {
        "id": "l4Ja_zgftwe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal_images_path = os.path.join(balanced_dataset_path, 'Normal', 'images')\n",
        "num_covid_images = len(os.listdir(os.path.join(balanced_dataset_path, 'COVID', 'images')))\n",
        "normal_image_files = os.listdir(normal_images_path)\n",
        "\n",
        "print(f'Before: {num_covid_images} Covid images / {len(normal_image_files)} Normal images')\n",
        "\n",
        "images_to_delete = random.sample(normal_image_files, len(normal_image_files) - num_covid_images)\n",
        "for image_file in images_to_delete:\n",
        "  image_path = os.path.join(normal_images_path, image_file)\n",
        "  os.remove(image_path)\n",
        "\n",
        "print(f'After: {num_covid_images} Covid images / {len(os.listdir(normal_images_path))} Normal images')"
      ],
      "metadata": {
        "id": "QDcVUK38MPqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####CSV creation, Create the new dataset folder, Convert all images to grayscale"
      ],
      "metadata": {
        "id": "5nryAKcWuCi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for every image in the dataset, register the name and class within a CSV (train or test), convert the non-gray image into gray images (needed to calculate mean and std for Normalization) and move all the images into a new dataset folder partitioned train/test\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "class_encoding = {class_name: idx for idx, class_name in enumerate(classes)}\n",
        "\n",
        "with open(train_csv_path, 'w', newline='') as train_csv_file, open(test_csv_path, 'w', newline='') as test_csv_file:\n",
        "  train_csv_writer = csv.writer(train_csv_file)\n",
        "  test_csv_writer = csv.writer(test_csv_file)\n",
        "\n",
        "  # Header\n",
        "  train_csv_writer.writerow(['Index_Name', 'Class'])\n",
        "  test_csv_writer.writerow(['Index_Name', 'Class'])\n",
        "\n",
        "  for class_name in classes:\n",
        "    class_dir = os.path.join(balanced_dataset_path, class_name, 'images')\n",
        "    images = os.listdir(class_dir)\n",
        "\n",
        "    train_images, test_images = train_test_split(images, test_size=TEST_SIZE, random_state=SEED)\n",
        "\n",
        "    for image in train_images:\n",
        "      # Write into the CSV\n",
        "      index_name = f\"{image}\"\n",
        "      class_label = class_encoding[class_name]\n",
        "      train_csv_writer.writerow([index_name, class_label])\n",
        "\n",
        "      # Move files\n",
        "      source_path = os.path.join(class_dir, image)\n",
        "      pre_image = np.array(Image.open(source_path))\n",
        "\n",
        "      # Check if they are not grey scale\n",
        "      if len(pre_image.shape) > 2:\n",
        "        grayscale_image = np.dot(pre_image[..., :3], [0.299, 0.587, 0.114])\n",
        "        grayscale_image = Image.fromarray(grayscale_image.astype(np.uint8))\n",
        "        os.remove(source_path)\n",
        "        grayscale_image.save(source_path)\n",
        "        print('Modified: ', source_path)\n",
        "\n",
        "      if os.path.exists(source_path) == True:\n",
        "        destination_path = os.path.join(train_dir, image)\n",
        "        shutil.copy(source_path, destination_path)\n",
        "      else:\n",
        "        raise Exception('FILE NOT FOUND')\n",
        "\n",
        "    for image in test_images:\n",
        "      index_name = f\"{image}\"\n",
        "      class_label = class_encoding[class_name]\n",
        "      test_csv_writer.writerow([index_name, class_label])\n",
        "\n",
        "      source_path = os.path.join(class_dir, image)\n",
        "      pre_image = np.array(Image.open(source_path))\n",
        "\n",
        "      if len(pre_image.shape) > 2:\n",
        "        grayscale_image = np.dot(pre_image[..., :3], [0.299, 0.587, 0.114])\n",
        "        grayscale_image = Image.fromarray(grayscale_image.astype(np.uint8))\n",
        "        os.remove(source_path)\n",
        "        grayscale_image.save(source_path)\n",
        "        print('Modified: ', source_path)\n",
        "\n",
        "      if os.path.exists(source_path) == True:\n",
        "        destination_path = os.path.join(test_dir, image)\n",
        "        shutil.copy(source_path, destination_path)\n",
        "      else:\n",
        "        raise Exception('FILE NOT FOUND')"
      ],
      "metadata": {
        "id": "r-2iX1bL_Dg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if there is a non-grayscale image"
      ],
      "metadata": {
        "id": "R-E7vZT9PsM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def is_grayscale(image_path):\n",
        "    # Open the image\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Check if it's a grayscale image\n",
        "    return img.mode == 'L'\n",
        "\n",
        "for root, dirs, files in os.walk(new_dataset_name):\n",
        "    for file in files:\n",
        "\n",
        "        if file.endswith('.jpg') or file.endswith('.png'):\n",
        "            image_path = os.path.join(root, file)\n",
        "            if not is_grayscale(image_path):\n",
        "              raise Exception('Error: Multiple channels detected')\n",
        "        else:\n",
        "          raise Exception('Error: File format not supported')\n",
        "print(\"All the images are grayscale\")\n"
      ],
      "metadata": {
        "id": "Ad83YAcYPqEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checkings"
      ],
      "metadata": {
        "id": "oiU1zi4iDtN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Plot class occurrencies"
      ],
      "metadata": {
        "id": "Xu9Qr4S9urY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df = pd.read_csv(test_csv_path)\n",
        "\n",
        "train_counts = train_df['Class'].value_counts().sort_index()\n",
        "test_counts = test_df['Class'].value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.bar(train_counts.index, train_counts.values, color='blue', alpha=0.7, label='Train')\n",
        "plt.bar(test_counts.index, test_counts.values, color='orange', alpha=0.7, label='Test')\n",
        "\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Number of Images per Class in Train and Test Sets')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a51_FZWADzLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check image dimensions"
      ],
      "metadata": {
        "id": "nAMtTqdnRSYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All images should be 299 x 299, This script doesn't check the channels\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def get_image_dimensions(image_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        return img.size\n",
        "\n",
        "# Loop through each image in the training folder\n",
        "train_prev_dim = (0,0)\n",
        "test_prev_dim = (0,0)\n",
        "for img in os.listdir(train_dir):\n",
        "  if img.endswith(\".jpg\") or img.endswith(\".png\"):\n",
        "    img_path = os.path.join(train_dir, img)\n",
        "    dimensions = get_image_dimensions(img_path)\n",
        "\n",
        "    if train_prev_dim != dimensions:\n",
        "      print(\"Train image dimensions: \", dimensions)\n",
        "      train_prev_dim = dimensions\n",
        "\n",
        "for img in os.listdir(test_dir):\n",
        "  if img.endswith(\".jpg\") or img.endswith(\".png\"):\n",
        "    img_path = os.path.join(test_dir, img)\n",
        "    dimensions = get_image_dimensions(img_path)\n",
        "\n",
        "    if test_prev_dim != dimensions:\n",
        "      print(\"Test image dimensions: \", dimensions)\n",
        "      test_prev_dim = dimensions"
      ],
      "metadata": {
        "id": "WeSt2t8wOIbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prepare Dataset**"
      ],
      "metadata": {
        "id": "XnuUk8y4BXEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset creation"
      ],
      "metadata": {
        "id": "PnVDGsUicPf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchvision.transforms import v2\n",
        "import torchvision.transforms as v2\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "resizedTransform = v2.Compose([\n",
        "  # v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
        "  # v2.RandomHorizontalFlip(p=0.5),\n",
        "  # ToFloatTensor()\n",
        "  v2.ToTensor(), # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
        "  # v2.ToDtype(torch.float32, scale=True)\n",
        "  # v2.Normalize(mean=[0.485], std=[0.229]),\n",
        "  if is_conv = False:\n",
        "    v2.Resize(size=(150,150))\n",
        "])\n",
        "\n",
        "class CovidDataset(Dataset):\n",
        "  def __init__(self, train_images_folder, test_images_folder, path_to_train_csv, path_to_test_csv, train=True, transform=None):\n",
        "    super().__init__()\n",
        "    self.train_data = pd.read_csv(path_to_train_csv)\n",
        "    self.test_data = pd.read_csv(path_to_test_csv)\n",
        "    self.train_images_folder = train_images_folder\n",
        "    self.test_images_folder = test_images_folder\n",
        "    self.images_files = os.listdir(train_images_folder)\n",
        "    self.transform = transform\n",
        "    self.train = train\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.train_data.shape[0] if self.train else self.test_data.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    if self.train:\n",
        "      image_file, label = self.train_data.iloc[index]\n",
        "      image = np.array(Image.open(os.path.join(self.train_images_folder, image_file)))\n",
        "    else:\n",
        "      image_file, label = self.test_data.iloc[index]\n",
        "      image = np.array(Image.open(os.path.join(self.test_images_folder, image_file)))\n",
        "\n",
        "    if self.transform:\n",
        "      # image = self.transform(image)[\"image\"]\n",
        "      image = self.transform(image)\n",
        "\n",
        "\n",
        "\n",
        "    return image, label, image_file"
      ],
      "metadata": {
        "id": "BId3UUvo6Fkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset Normalization"
      ],
      "metadata": {
        "id": "HtsaSshucwSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you think data can fit in your memory, change it_fits to True\n",
        "if normalize:\n",
        "\n",
        "# Compute mean and std of the data\n",
        "  it_fits = False\n",
        "\n",
        "  dataset = CovidDataset(\n",
        "    train_images_folder = train_dir,\n",
        "    test_images_folder = test_dir,\n",
        "    path_to_train_csv = train_csv_path,\n",
        "    path_to_test_csv = test_csv_path,\n",
        "    transform = resizedTransform\n",
        "  )\n",
        "\n",
        "  if it_fits:\n",
        "    loader = DataLoader(\n",
        "      dataset=dataset, batch_size=len(pd.read_csv(train_csv_path)), num_workers=1, shuffle=True, pin_memory=True\n",
        "    )\n",
        "    data = next(iter(loader))\n",
        "    mean = data[0].mean()\n",
        "    std = data[0].std()\n",
        "    print('Mean: ', mean, '\\nStd: ', std)\n",
        "\n",
        "  else:\n",
        "\n",
        "    loader = DataLoader(\n",
        "      dataset=dataset, batch_size=1000, num_workers=0, shuffle=True, pin_memory=True\n",
        "    )\n",
        "    num_of_pixels = len(pd.read_csv(train_csv_path)) *299*299\n",
        "    total_sum = 0\n",
        "    for batch in loader:\n",
        "      total_sum += batch[0].sum()\n",
        "      # since get item returned image, label, name_of_the_image, batch is composed of 3 elements: [0]: series of 1000 images, [1]: series of 1000 labels, [2]: series of 1000 image names\n",
        "    mean = total_sum/num_of_pixels\n",
        "\n",
        "    sum_of_squared_error = 0\n",
        "    for batch in loader:\n",
        "      sum_of_squared_error += ((batch[0]-mean).pow(2)).sum()\n",
        "    std = torch.sqrt(sum_of_squared_error/num_of_pixels)\n",
        "\n",
        "    print('Mean pre-normalization: ', mean)\n",
        "    print('Standard Deviation pre-normalization: ', std)\n",
        "\n",
        "  # Plot not normalized data\n",
        "\n",
        "  num_bins = 50\n",
        "  hist_sum = np.zeros(num_bins)\n",
        "  # Define bin edges explicitly for the range [0, 1]\n",
        "  bin_edges = np.linspace(-2, 2, num_bins + 1)\n",
        "  for batch in loader:\n",
        "      batch_data = batch[0].numpy()\n",
        "      hist_batch, _ = np.histogram(batch_data, bins=bin_edges)\n",
        "      hist_sum += hist_batch\n",
        "\n",
        "  plt.bar(bin_edges[:-1], hist_sum, width=(bin_edges[1] - bin_edges[0]))\n",
        "  plt.axvline(mean)\n",
        "  plt.show()\n",
        "\n",
        "  # Normalize the data\n",
        "\n",
        "  resizedTransform = v2.Compose([\n",
        "    v2.ToTensor(), # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
        "    v2.Resize(size=(150,150)),\n",
        "    v2.Normalize(mean=mean, std=std)\n",
        "  ])\n",
        "\n",
        "  normDataset = CovidDataset(\n",
        "    train_images_folder = train_dir,\n",
        "    test_images_folder = test_dir,\n",
        "    path_to_train_csv = train_csv_path,\n",
        "    path_to_test_csv = test_csv_path,\n",
        "    transform = resizedTransform\n",
        "  )\n",
        "\n",
        "  normLoader = DataLoader(\n",
        "    dataset=normDataset, batch_size=1000, num_workers=0, shuffle=True, pin_memory=True\n",
        "  )\n",
        "\n",
        "  num_of_pixels = len(pd.read_csv(train_csv_path)) *299*299\n",
        "  total_sum = 0\n",
        "  for batch in normLoader:\n",
        "    total_sum += batch[0].sum()\n",
        "    # since get item returned image, label, name_of_the_image, batch is composed of 3 elements: [0]: series of 1000 images, [1]: series of 1000 labels, [2]: series of 1000 image names\n",
        "  mean = total_sum/num_of_pixels\n",
        "\n",
        "  sum_of_squared_error = 0\n",
        "  for batch in normLoader:\n",
        "    sum_of_squared_error += ((batch[0]-mean).pow(2)).sum()\n",
        "  std = torch.sqrt(sum_of_squared_error/num_of_pixels)\n",
        "\n",
        "  print('Mean post-normalization: ', mean)\n",
        "  print('Standard Deviation post-normalization: ', std)\n",
        "\n",
        "  # Plot normalize data\n",
        "\n",
        "  num_bins = 50\n",
        "  hist_sum = np.zeros(num_bins)\n",
        "  # Define bin edges explicitly for the range [0, 1]\n",
        "  bin_edges = np.linspace(-2, 2, num_bins + 1)\n",
        "  for batch in normLoader:\n",
        "      batch_data = batch[0].numpy()\n",
        "      hist_batch, _ = np.histogram(batch_data, bins=bin_edges)\n",
        "      hist_sum += hist_batch\n",
        "\n",
        "  plt.bar(bin_edges[:-1], hist_sum, width=(bin_edges[1] - bin_edges[0]))\n",
        "  plt.axvline(mean)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "xxLinw1ooWfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create the Networks**"
      ],
      "metadata": {
        "id": "I8Eor9e-eqLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup"
      ],
      "metadata": {
        "id": "6htszTNv7fIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Train and Test data loading"
      ],
      "metadata": {
        "id": "28vdULYYvC-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CovidDataset(\n",
        "  train_images_folder = train_dir,\n",
        "  test_images_folder = test_dir,\n",
        "  path_to_train_csv = train_csv_path,\n",
        "  path_to_test_csv = test_csv_path,\n",
        "  transform = resizedTransform\n",
        ")\n",
        "\n",
        "test_dataset = CovidDataset(\n",
        "  train_images_folder = train_dir,\n",
        "  test_images_folder = test_dir,\n",
        "  path_to_train_csv = train_csv_path,\n",
        "  path_to_test_csv = test_csv_path,\n",
        "  train = False,\n",
        "  transform = resizedTransform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "  dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=0, shuffle=True, pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "  dataset=test_dataset, batch_size=BATCH_SIZE, num_workers=0, shuffle=False, pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "yZW-GZDEWjKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Networks creation"
      ],
      "metadata": {
        "id": "GZgBP6duvKEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 8, 3)\n",
        "    self.pool = nn.MaxPool2d(2, 2) # kernel size 2 and stride 2\n",
        "    self.conv2 = nn.Conv2d(8, 16, 3)\n",
        "\n",
        "    self.fc1 = nn.Linear(16*36*36, 5000)\n",
        "    self.fc2 = nn.Linear(5000, NUM_CLASSES)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "    x = x.view(-1, 16*36*36)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        " class FCNet(nn.Module):\n",
        "   def __init__(self):\n",
        "     super(FCNet, self).__init__()\n",
        "     self.fc1 = nn.Linear(150*150, 5000)\n",
        "     self.fc2 = nn.Linear(5000, 100)\n",
        "     self.fc3 = nn.Linear(100, NUM_CLASSES)\n",
        "     self.dropout1 = nn.Dropout2d(0.25)\n",
        "     self.dropout2 = nn.Dropout2d(0.5)\n",
        "\n",
        "\n",
        "   def forward(self, x):\n",
        "     x = x.view(-1, 150*150)\n",
        "     x = F.relu(self.fc1(x))\n",
        "     x = self.dropout1(x)\n",
        "     x = F.relu(self.fc2(x))\n",
        "     x = self.dropout2(x)\n",
        "     x = self.fc3(x)\n",
        "     return x"
      ],
      "metadata": {
        "id": "iy5b6DBZf8tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train and Test"
      ],
      "metadata": {
        "id": "UPqQfLvFiqvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Cross validation"
      ],
      "metadata": {
        "id": "uXt4O65Z1VGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enable cross validation, we need to merge the train and test folder so that we can partition train and test set iteratively. The we will create another dataset from this folder and partition train and test set using the subset pytorch function"
      ],
      "metadata": {
        "id": "v0TtAuWueHn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "train_dir = 'Covid_Dataset/train'\n",
        "test_dir = 'Covid_Dataset/test'\n",
        "full_dir = 'Covid_Dataset/full'\n",
        "\n",
        "def copy_files(src_dir, dst_dir):\n",
        "    # Create the destination directory if it doesn't exist\n",
        "    if not os.path.exists(dst_dir):\n",
        "        os.makedirs(dst_dir)\n",
        "\n",
        "    # Copy files from the source\n",
        "    for filename in os.listdir(src_dir):\n",
        "        src_path = os.path.join(src_dir, filename)\n",
        "        dst_path = os.path.join(dst_dir, filename)\n",
        "\n",
        "        # Check if the file doesn't already exist\n",
        "        if not os.path.exists(dst_path):\n",
        "            shutil.copy(src_path, dst_path)\n",
        "        else:\n",
        "            print(f\"File {filename} already exists in the destination directory.\")\n",
        "\n",
        "# Copy files from train and test directories to the full directory\n",
        "copy_files(train_dir, full_dir)\n",
        "copy_files(test_dir, full_dir)\n",
        "\n",
        "print(\"Files have been copied to the 'full' directory.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "CbGrI7tnzBcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class CombinedDataset(Dataset):\n",
        "    def __init__(self, folder, transform=None):\n",
        "        self.folder = folder\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(dp, f) for dp, dn, filenames in os.walk(folder) for f in filenames if os.path.splitext(f)[1].lower() in ['.png', '.jpg', '.jpeg', '.bmp', '.gif']]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_paths[idx]\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        class_encoding = {class_name: idx for idx, class_name in enumerate(classes)}\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label_str = img_name.split(os.sep)[-1].split('-')[0]\n",
        "        # Convert class into label\n",
        "        label = class_encoding[label_str]\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "BgjvuJjL2KbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "full_dataset = CombinedDataset(folder='Covid_Dataset/full', transform=resizedTransform)\n",
        "\n",
        "k_folds = 5\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# List of accuracies of each fold. Needed to calculate its average at the end\n",
        "fold_accuracies = []\n",
        "\n",
        "# K-Fold Cross Validation model evaluation\n",
        "for fold, (train_ids, val_ids) in enumerate(kfold.split(full_dataset)):\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "\n",
        "    # Create subsets\n",
        "    train_subset = torch.utils.data.Subset(full_dataset, train_ids)\n",
        "    val_subset = torch.utils.data.Subset(full_dataset, val_ids)\n",
        "\n",
        "    # Define data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle = True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle = False\n",
        "    )\n",
        "\n",
        "    # Set model to FCNet() or ConvNet()\n",
        "    model = ConvNet() if is_conv else FCNet()\n",
        "\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    loss_fun = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    num_batches_in_train_dataset = len(train_loader)\n",
        "\n",
        "    training_accuracy_list = []\n",
        "    testing_accuracy_list = []\n",
        "\n",
        "    # For the confusion matrix i want the last epoch of testing performance\n",
        "    last_epoch_predictions = []\n",
        "    last_epoch_labels = []\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "      model.train()\n",
        "      for i, data in tqdm(enumerate(train_loader)):\n",
        "        images, labels = data\n",
        "\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = loss_fun(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      print('TRAINING END')\n",
        "\n",
        "      # Calculate accuracy of training and testing at the end of the training epoch\n",
        "\n",
        "      num_correct_train = 0\n",
        "      num_samples_train = 0\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for images, labels in train_loader:\n",
        "\n",
        "          images = images.to(DEVICE)\n",
        "          labels = labels.to(DEVICE)\n",
        "          outputs = model(images)\n",
        "\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "          num_samples_train += labels.size(0)\n",
        "          num_correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "      training_accuracy = num_correct_train / num_samples_train\n",
        "      training_accuracy_list.append(training_accuracy)\n",
        "\n",
        "      num_correct_test = 0\n",
        "      num_samples_test = 0\n",
        "      all_predictions = []\n",
        "      all_labels = []\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "\n",
        "          images = images.to(DEVICE)\n",
        "          labels = labels.to(DEVICE)\n",
        "          outputs = model(images)\n",
        "\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "          all_predictions.append(predicted.cpu().data.numpy())\n",
        "          all_labels.append(labels.cpu().data.numpy())\n",
        "\n",
        "          num_samples_test += labels.size(0)\n",
        "          num_correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "          # if it is the last epoch\n",
        "          if epoch == NUM_EPOCHS-1:\n",
        "            last_epoch_predictions.append(predicted.cpu().data.numpy())\n",
        "            last_epoch_labels.append(labels.cpu().data.numpy())\n",
        "\n",
        "\n",
        "      testing_accuracy = num_correct_test / num_samples_test\n",
        "      testing_accuracy_list.append(testing_accuracy)\n",
        "\n",
        "      # Calulculate Precision and Recall after flattening the predictions and labels\n",
        "      flattened_array1 = np.concatenate(all_predictions).ravel()\n",
        "      result_list1 = flattened_array1.tolist()\n",
        "      prediction_list = np.array(result_list1)\n",
        "\n",
        "      flattened_array2 = np.concatenate(all_labels).ravel()\n",
        "      result_list2 = flattened_array2.tolist()\n",
        "      labels_list = np.array(result_list2)\n",
        "\n",
        "      precision, recall, _, __ = precision_recall_fscore_support(labels_list, prediction_list,average='binary')\n",
        "      print('\\nFC Precision: ', precision)\n",
        "      print('FC Recall: ', recall)\n",
        "\n",
        "\n",
        "    # Append this iteration's accuracy\n",
        "    fold_accuracies.append(testing_accuracy)\n",
        "    print(fold_accuracies)\n",
        "\n",
        "    # Flat the labels and predictions of the last epoch\n",
        "    flattened_last_epoch_predictions_array = np.concatenate(last_epoch_predictions).ravel()\n",
        "    flattened_last_epoch_predictions_list = flattened_last_epoch_predictions_array.tolist()\n",
        "    last_epoch_predictions_list = np.array(flattened_last_epoch_predictions_list)\n",
        "\n",
        "    flattened_last_epoch_labels_array = np.concatenate(all_labels).ravel()\n",
        "    flattened_last_epoch_labels_list = flattened_last_epoch_labels_array.tolist()\n",
        "    last_epoch_labels_list = np.array(flattened_last_epoch_labels_list)\n",
        "\n",
        "    # The confusion matrix has information of only the last epoch\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    conf_matrix = confusion_matrix(last_epoch_labels_list, last_epoch_predictions_list)\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    # The accuracy charts take into account the accuracy on all the epochs\n",
        "    epochs = range(1, NUM_EPOCHS + 1)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(epochs, training_accuracy_list, label='Training Accuracy')\n",
        "    plt.plot(epochs, testing_accuracy_list, label='Testing Accuracy')\n",
        "    plt.title('Training and Testing Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "print('FINAL ACCURACY: ', sum(fold_accuracies)/5)\n",
        "\n"
      ],
      "metadata": {
        "id": "ERF4nDnmyZfY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "BBx2plmvC1Vn",
        "GLRnWIniC8VD",
        "4D_6Vw2PDJOD",
        "GVTkYCXdg8Q9",
        "6_MFPSGsteTq",
        "qbUriMJWtpnE",
        "l4Ja_zgftwe7",
        "5nryAKcWuCi5",
        "oiU1zi4iDtN-",
        "Xu9Qr4S9urY9",
        "XnuUk8y4BXEM",
        "PnVDGsUicPf3",
        "HtsaSshucwSo",
        "I8Eor9e-eqLZ",
        "6htszTNv7fIQ",
        "28vdULYYvC-e",
        "GZgBP6duvKEK",
        "UPqQfLvFiqvL",
        "uXt4O65Z1VGR"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}